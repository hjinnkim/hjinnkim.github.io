---
title: "[Paper Review] Denoising Diffusion Probabilistic Models (NeurIPS 2020)"
categories:
  - Paper Review
tags:
  - Generative Models
  - Diffusion Models
  
excerpt: "[Paper Review] Denoising Diffusion Probabilistic Models (NeurIPS 2020)"

last_modified_at: 2025-01-18T22:00:00
---

# Denoising Diffusion Probabilistic Models (NeurIPS 2020)

> Denoising Diffusion Probabilistic Models. [[Paper](https://arxiv.org/abs/2006.11239)] [[Github](https://github.com/hojonathanho/diffusion)] \\
> Jonathan Ho, Ajay Jain, Pieter Abbeel \\
> Jun 19th 2020

Diffusion Model의 (거의) 시작점을 알린 논문이다. 이 논문을 처음 보았을 때 굉장히 어려웠었고, 그래서 이 논문을 가장 먼저 포스팅해보려고 한다. 혹시 관련 개념을 잘 모른다면, [[Intro to Diffusion Models] (1) What is Diffusion?](/study/what-is-diffusion/)를 보고 오시는 것을 추천한다.

또한, Diffusion Model의 수학을 굉장히 잘 설명해둔 [Understanding Diffusion Models: A Unified Perspective](https://arxiv.org/abs/2208.11970) 역시 큰 도움이 될 것이다. 이 포스팅 이후, 해당 논문을 리뷰할 예정이다.

## Background

Diffusion Model은 다음과 같은 형태를 띈다.

$$
x_0:=x(0)\sim p_{data}(x)\underset{p_\theta(x_0 \vert x_1)}{\overset{q(x_1 \vert x_0)}{\rightleftarrows}} x_1 \rightleftarrows \cdots \rightarrow x_{T-1} \underset{p_\theta(x_{T-1} \vert x_{T})}{\overset{q(x_{T} \vert x_{T-1})}{\rightleftarrows}} x_T:=x(1),\ x(1)\approx z\sim \mathcal N(0,I)
$$

이를 모델 $p_\theta$의 관점에서 표현하면, Reverse Diffusion Process를 묘사하는 다음의 latent variable model로 표현된다. 

$$
p_\theta(x_{0:T}):=p(x_T)\prod^T_{t=1}p_\theta(x_{t-1}\vert x_t),\quad p_\theta(x_{t-1}\vert x_t)=\mathcal N(x_{t-1}; \mu_\theta(x_t,t),\Sigma_\theta(x_t,t))
$$

이때, $p_\theta(x_{0:T})$는 posterior이자, Forward Diffusion Process인 

$$
q(x_{1:T}\vert x_0):=\prod^T_{t=1}q(x_t\vert x_{t-1}),\quad q(x_t\vert x_{t-1}):=\mathcal N(x_t;\sqrt{1-\beta_t}x_{t-1},\beta_t I)
$$

를 근사하도록 학습한다. 

<details>
<summary>Reverse Diffusion Process로 왜 Forward Diffusion Process를 근사하는가?</summary>
<div>

 만약 $p_\theta$가 $q$를 잘 근사한다면, $p_\theta(x_t)$가 묘사하는 분포와 $q(x_t)$가 묘사하는 분포가 동일해야한다. 따라서, Forward Diffusion Process를 묘사하는 $q$의 분포를 $p_\theta$를 통해 근사하는 것이다.

</div>
</details>
<br>

이때, $q(x_T\vert x_0)\approx \mathcal N(x_T;0,I)$여야 하기 때문에, $q(x_t\vert x_{0})$은 $t\rightarrow T$로 진행될 수록 $x_{t-1}$의 영향력을 줄여나가면서, variance를 $I$에 가깝게 만들어야 한다. 따라서 variance schedule, $\beta_1,\dots,\beta_T$는 $0<\beta_1,<\beta_2<\cdots<\beta_{T-1}<\beta_T<1$ 로 정의된다. 따라서, 이 과정을 거치면, $x_{t-1}$을 scaling down 하고 gaussian noise를 더하는 형태로 Diffusion Process를 진행하게 된다. 이때, variance scheduling ($\beta_t$)의 설정은 논문마다 다르며, 이후 논문들에서는 효과적인 variacne scheduling을 찾기 위한 노력을 하기도 한다.

학습은 variational bound on negative log-likelihood를 최적화하여 $p_\theta$를 학습한다. 

$$
\begin{align}
\mathbb E\left[{-\log p_\theta(x_{0})}\right] &\leq \mathbb E_{q}\left[{ - \log \frac{p_\theta(x_{0:T})}{q(x_{1:T} | x_0)}}\right] \\ 
& = \mathbb{E}_q\left[ -\log p(x_T) - \sum_{t \geq 1} \log \frac{p_\theta(x_{t-1} | x_t)}{q(x_t|x_{t-1})} \right] := L
\end{align}
$$

이때, $\leq$는 [Jensen's inequality](https://en.wikipedia.org/wiki/Jensen%27s_inequality)에 의해 성립된다. $L$을 최적화하는 것은 $\log p_\theta(x_{0})$을 최대화하는 것과 같으므로, data $x_0$을 sampling할 확률을 높이는 방향으로 $p_\theta$를 학습한다는 뜻이다.

## Reparameterization trick

왜 gaussian noise를 더한다는 것인가? 이는 gaussian distribution에서의 sampling 과정을 살펴보면 명확해진다. (statistical machine learning에서 주로 쓰이며) 딥러닝에서는 [VAE 논문](https://arxiv.org/abs/1312.6114)에서 사용하여 유명해진 *Reparameterization trick*을 사용하여 gaussian distribution에서의 sampling을 진행한다. Back-propagation을 통해 gaussian distribution을 묘사하는 $\mu,\sigma^2$을 학습하기 위해서는, $\mu,\sigma$에 gradient가 흐르도록 $z\sim\mathcal N(\mu,\sigma^2)$을 sampling 해야한다. Reparameterization trick은 $z$를 다음과 같은 형태로 샘플링한다.

$$
z=\mu+\sigma\epsilon,\quad  \epsilon\sim \mathcal N(0,I)
$$

이 형태를 고려하여 $q(x_t\vert x_{t-1}):=\mathcal N(x_t;\sqrt{1-\beta_t}x_{t-1},\beta_t I)$를 살펴보면

$$
x_t=\sqrt{1-\beta_t}x_{t-1}+\beta_t I\epsilon_t,\quad \epsilon_t\sim \mathcal N(0,I)
$$

형태를 띈다. $0<\beta_t<1$ 이기 때문에, $x_t$에서 $x_{t-1}$은 scaling down되고,  $\beta_t$만큼 scaling된 gaussian noise $\epsilon_t$가 $\sqrt{1-\beta_t}x_{t-1}$에 더해진 형태로 $x_t$가 sampling 되는 것이다.

## Toward Efficients Experssions for Diffusion Model Training

만약 $x_t$에 대해서 학습하기 위해서 모든 $x_0,x_1,\dots,x_{t-1}$의 diffusion step을 거쳐야한다면 굉장히 오랜 시간이 걸릴 것이다. DDPM에서는 임의의 time step $t$에 대해 $x_t$를 샘플링할 수 있는 closed form을 보였다.

$$
q(x_t\vert x_0)=\mathcal N(x_t;\sqrt{\bar \alpha_t},(1-\bar\alpha_t)I)
$$

이때, $\alpha_t:=1-\beta_t$, $\bar\alpha_t:=\prod^t_{s=1}\alpha_s$ 이다.

<details>
<summary>Derivation for $q(x_t \vert x_0)$</summary>
<div>

[Understanding Diffusion Models: A Unified Perspective](https://arxiv.org/abs/2208.11970)에서도 증명을 해줄테지만, 내가 찾아봤던 방식은 Fourier Transform을 사용해서, 정리해본다.

  ### Background [3.3 Combining Gaussian variables](https://www.astro.ubc.ca/people/jvw/ASTROSTATS/Answers/Chap3/combining%20gaussians.pdf)

  Let $g_1(t)=e^{-at^2}$, the Fourier transform of $g_1(t)$ is given as follows:

  $$
  G_1(w)=\int e^{iwt}e^{-at^2}dt=\sqrt{\frac{\pi}{a}}e^{-w^2/4a}
  $$

  For $g_1(t)=\frac{1}{\sqrt{2\pi}\sigma_1}e^{-t^2/(2\sigma_1^2)}$

  $$
  G_1(w)=e^{-\sigma_1^2\cdot w^2/2}
  $$

  If $\bar g_1(t)=\frac{1}{\sqrt{2\pi}\sigma_1}e^{-(t-\mu_1)^2/(2\sigma_1^2)}$, then $\bar G_1(w)=e^{i\mu_1w}e^{-\sigma_1^2\cdot w^2/2}=e^{i\mu_1w}G_1(w)$

  For convolving two gaussian distributions, which is adding two gaussian noises, $g_1(t):=\mathcal N(\mu_1,\sigma_1)$, $g_2(t):=\mathcal N(\mu_2,\sigma_2)$

  $$
  g_1(t)*g_2(t) \overset{FT}{\leftrightarrow} G_1(w)G_2(w)^*=e^{iw\mu_1}e^{-\sigma_1^2\cdot w^2/2}\cdot e^{-iw\mu_2}e^{-\sigma_2^2\cdot w^2/2}=e^{iw(\mu_1-\mu_2)}e^{-(\sigma_1^2+\sigma_2^2)\cdot w^2/2}
  $$

  If two gaussian distributions share same mean, $\mu_1=\mu_2=\mu$,

  $$
  G_1(w)G_2^*=e^{-(\sigma_1^2+\sigma_2^2)\cdot w^2/2}
  $$

  which is just another gaussian distribution with a variance $\sigma_1^2+\sigma_2^2$. Then, 

  $$
  g_1(t)*g_2(t)=\mathcal N(0, \sigma_1^2+\sigma_2^2)=\frac{1}{\sqrt{2\pi(\sigma_1^2+\sigma_2^2)}}e^{-t^2/2(\sigma_1^2+\sigma_2^2)}
  $$
  
  ### Derivation for $q(x_t\vert x_0) = \mathcal N(x_t; \sqrt{\bar\alpha_t}, (1-\bar\alpha_t)I)$

  - $q(x_t\vert x_{t-1}):=\mathcal N(x_t; \sqrt{1-\beta_t}x_{t-1},\beta_tI)$
  - $\alpha_t:=1-\beta_t$
  - $\bar\alpha_t:=\prod^t_{s=1}\alpha_s$.

  From $x_t\sim q(x_t\vert x_{t-1})$ and $x_{t-1}\sim q(x_{t-1}\vert x_{t-2})$
  $$
  \begin{align}
      x_{t-1}&=\sqrt{1-\beta_{t-1}}x_{t-2}+\beta_{t-1}\epsilon_{t-1},\quad \text{where } \epsilon_{t-1}\sim\mathcal N(0,I) \\
      & =\sqrt{\alpha_{t-1}}x_{t-2}+\sqrt{1-\alpha_{t-1}}\epsilon_{t-1} \\
      x_t & =\sqrt{1-\beta_t}x_{t-1}+\beta_t\epsilon_t,\quad \text{where } \epsilon_t\sim\mathcal N(0,I) \\
      & =\sqrt{\alpha_t}\textcolor{red}{x_{t-1}}+\sqrt{1-\alpha_t}\epsilon_t \\
      & =\sqrt{\alpha_t}(\textcolor{red}{\sqrt{\alpha_{t-1}}x_{t-2}+\sqrt{1-\alpha_{t-1}}\epsilon_{t-1}})+\sqrt{1-\alpha_t}\epsilon_t \\
      &=\sqrt{\alpha_t\alpha_{t-1}}x_{t-2}+\sqrt{\alpha_t}\sqrt{1-\alpha_{t-1}}\epsilon_{t-1}+\sqrt{1-\alpha_t}\epsilon_t
  \end{align}
  $$

  Here, adding two gaussian noises is same as convolving two gaussian distributions. Therefore, 

  $$
  \begin{align}
  \sqrt{\alpha_t}\sqrt{1-\alpha_{t-1}}\epsilon_{t-1}+\sqrt{1-\alpha_t}\epsilon_t=\bar\epsilon&\sim \mathcal N(0, \alpha_t(1-\alpha_{t-1})I)*\mathcal N(0,(1-\alpha_{t-1})I) \\
  \bar\epsilon_t & \sim\mathcal N(0,(\alpha_t(1-\alpha_{t-1})+(1-\alpha_{t-1}))I) \\
  \bar\epsilon_t & \sim\mathcal N(0, (1-\alpha_t\alpha_{t-1})I) \\
  \bar\epsilon_t=\sqrt{1-\alpha_t\alpha_{t-1}}\epsilon^* & \sim\mathcal N(0,(1-\alpha_t\alpha_{t-1})I),\quad \epsilon^*\sim\mathcal N(0,I)
  \end{align}
  $$

  Therfore, eq (8) becomes

  $$
  \begin{align*}
  x_t&=\sqrt{\alpha_t\alpha_{t-1}}x_{t-2}+\underbrace{\sqrt{\alpha_t}\sqrt{1-\alpha_{t-1}}\epsilon_{t-1}+\sqrt{1-\alpha_t}\epsilon_t}_{\bar\epsilon_t}\\
  &=\sqrt{\alpha_t\alpha_{t-1}}x_{t-2}+\sqrt{1-\alpha_t\alpha_{t-1}}\epsilon,\quad \epsilon\sim\mathcal N(0,I)
  \end{align*}
  $$

  If we repeat this steps, we can derive following closed from:

  $$
  \begin{align*}
  x_t&=\sqrt{\prod^t_{s=1}\alpha_s}x_{0}+\sqrt{1-\prod^t_{s=1}\alpha_s}\epsilon,\quad \epsilon\sim\mathcal N(0,I) \\
  &=\sqrt{\bar\alpha_t}x_0+\sqrt{1-\bar\alpha_t}\epsilon
  \end{align*}
  $$

  which is equal to

  $$
  x_t\sim q(x_t\vert x_0)=\mathcal N(x_t;\sqrt{\bar\alpha_t}x_0,(1-\bar\alpha_t)I)
  $$

</div>
</details>
<br>

위 식을 이용하여, **data $x_0$에서 임의의 time step $t$의 $x_t$를 직접적으로 샘플링이 가능하기 때문에 효율적으로 학습이 가능하다.**

한가지 기억할 점은, 우리의 모델 $p_\theta(x_{t-1}\vert x_t)$는 $x_t$를 input으로 받아 $x_{t-1}$을 예측하는 모델이기 때문에, 이를 학습시키기 위한 target $x_{t-1}$을 forward diffusion distribution $q(\cdot)$에서 샘플링할 수 있어야 한다. 위 식을 더욱 전개하여 posteior distribution $q(x_{t-1}\vert x_t,x_0)$을 얻을 수 있다.

Bayes' rule에 따라,

$$
\underbrace{q(x_{t-1}\vert x_{t},x_0)}_{posterior}=\frac{\overbrace{q(x_t\vert x_{t-1},x_0)}^{likelihood}\overbrace{q(x_{t-1}\vert x_0)}^{prior}}{\underbrace{q(x_t\vert x_0)}_{evidence}}=\frac{q(x_t\vert x_{t-1})q(x_{t-1}\vert x_0)}{q(x_t\vert x_0)}
$$

$q(x_t\vert x_{t-1}, x_0)$은 Markov Process를 가정하였기 때문에 $q(x_t\vert x_{t-1},x_0)=q(x_t\vert x_{t-1})$와 동일하다. 

normalization term을 배제하면 위 식은 다음 관계를 가지게 된다.

$$
\begin{align}
\frac{q(x_t\vert x_{t-1},x_0)q(x_{t-1}\vert x_0)}{q(x_t\vert x_0)} & \propto \exp\left(-\frac{1}{2}\left( \frac{(x_t-\sqrt{\alpha_t}x_{t-1})^2}{\beta_t} + \frac{(x_{t-1}-\sqrt{\bar\alpha_{t-1}}x_0)^2}{1-\bar\alpha_{t-1}}+\frac{(x_t-\sqrt{\bar\alpha_t}x_0)^2}{1-\bar\alpha_t}\right)\right) \\
&=
\end{align}
$$

이 식을 사용하여, 위의 최적화 식을 다음과 같이 수정이 가능하다.




$$
\mathbb{E}_q\left[ -\log p(x_T) - \sum_{t \geq 1} \log \frac{p_\theta(x_{t-1} | x_t)}{q(x_t|x_{t-1})} \right]=
$$